{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Metadatos import generaPathProyecto, RMSLE, logTransf, antilogTransf\n",
    "from CargaDatos import retornaSets\n",
    "from Preparacion import preparaDf, separacionEntrenaObjetivo\n",
    "from Modelo import definirModelo\n",
    "from CargaDatos import generaPath\n",
    "from Salida import generarEnvio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ggplot as gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validarModelo():\n",
    "    dScores = {'best' : -modelo.best_score_,\n",
    "               'train' : RMSLE(y_train, antilogTransf(modelo.predict(X_train))),\n",
    "               'test' : RMSLE(y_test, antilogTransf(modelo.predict(X_test)))}\n",
    "    print str('La mejor puntuacion de la crossvalidacion fue: {}\\n' +\n",
    "              'La puntuacion del entrenamiento fue: {}\\n' +\n",
    "              'La puntuacion de la prueba fue: {}').format(dScores['best'], dScores['train'], dScores['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecucion de rutina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_proyecto = generaPathProyecto()\n",
    "sets_df = retornaSets(path_proyecto = path_proyecto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepDf = preparaDf()\n",
    "df = prepDf.preparar(sets_df)\n",
    "X_train, X_test, y_train, y_test = separacionEntrenaObjetivo(df, semilla = 1962, prop_prueba= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelo = definirModelo()\n",
    "modelo.fit(X = X_train.values, y = logTransf(y_train).values.reshape(y_train.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentacion de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decisor__learning_rate': 0.02,\n",
       " 'decisor__max_depth': 8,\n",
       " 'decisor__max_features': 0.2,\n",
       " 'decisor__min_samples_leaf': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelo.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor puntuacion de la crossvalidacion fue: 0.0827127816879\n",
      "La puntuacion del entrenamiento fue: 0.0708121158123\n",
      "La puntuacion de la prueba fue: 0.181625717096\n"
     ]
    }
   ],
   "source": [
    "validarModelo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_envio = prepDf.preparar(sets_df, train_o_envio= 'test')\n",
    "generarEnvio(modelo, X_envio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
